# README.md

# ğŸ¤– AI Chat Assistant

A powerful conversational AI assistant built with LangGraph and Streamlit, featuring persistent chat threads, real-time streaming, and an intuitive web interface.

## âœ¨ Features

- ğŸ’¬ **Real-time Chat**: Stream responses token-by-token for immediate feedback
- ğŸ§µ **Thread Management**: Create multiple chat threads and switch between conversations
- ğŸ’¾ **Persistent Memory**: Chat history persists across sessions using SQLite
- ğŸ”„ **State Management**: Advanced conversation state handling with LangGraph
- ğŸ¨ **Clean UI**: Intuitive Streamlit interface with sidebar navigation
- âš¡ **Fast Responses**: Powered by Groq's high-performance language models

## ğŸš€ Live Demo

**[Try it live on Streamlit Cloud](https://chat-app.streamlit.app)** 

## ğŸ› ï¸ Technology Stack

- **Frontend**: Streamlit
- **AI Framework**: LangGraph + LangChain
- **Language Model**: Groq (OpenAI GPT-OSS-120B)
- **Database**: SQLite with LangGraph checkpointing
- **Deployment**: Streamlit Cloud

## ğŸ“‹ Prerequisites

- Python 3.10+
- Groq API key ([Get one here](https://console.groq.com/keys))

## ğŸ”§ Local Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/muhammadUsman31254/ChatApp.git
   cd langgraph-chat-app
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   # Create .env file
   echo "GROQ_API_KEY=your_groq_api_key_here" > .env
   ```

4. **Run the application**
   ```bash
   streamlit run app.py
   ```

5. **Open your browser** and navigate to `http://localhost:8501`

## ğŸš€ Deployment

### Streamlit Cloud Deployment

1. **Fork this repository** to your GitHub account

2. **Go to [Streamlit Cloud](https://share.streamlit.io)**

3. **Create new app** and connect to your forked repository

4. **Add secrets** in Streamlit Cloud dashboard:
   ```toml
   GROQ_API_KEY = "your_groq_api_key_here"
   ```

5. **Deploy** and your app will be live!

### Local Docker Deployment (Optional)

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY . /app

RUN pip install -r requirements.txt

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

## ğŸ“ Project Structure

```
langgraph-chat-app/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ workflow.py           # LangGraph workflow definition
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ secrets.toml     # Environment variables 
â”œâ”€â”€ .gitignore           # Git ignore file
â””â”€â”€ README.md           # This file
```

## ğŸ¯ How It Works

1. **LangGraph Workflow**: Defines a simple chat node that processes messages
2. **State Management**: Uses TypedDict to maintain conversation state
3. **Checkpointing**: SQLite database stores conversation history
4. **Streaming**: Real-time token streaming for better user experience
5. **Thread Management**: Each conversation gets a unique thread ID

## ğŸ™ Acknowledgments

- [LangGraph](https://langchain-ai.github.io/langgraph/) for the powerful agent framework
- [LangChain](https://langchain.com/) for the foundational tools
- [Streamlit](https://streamlit.io/) for the amazing web app framework  
- [Groq](https://groq.com/) for lightning-fast language model inference

## ğŸ“ Support

If you have any questions or run into issues, please [open an issue](https://github.com/muhammadUsman31254/ChatApp/issues) on GitHub.

---

**Made with â¤ï¸ using LangGraph and Streamlit**
